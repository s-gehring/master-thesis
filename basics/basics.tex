% !TeX root = ../Main.tex

\chapter{Basics}
\label{ch:basics}
In this chapter, the two most important technologies for the framework are explained. This is necessary to get an understanding of the technical difficulties it challenges and how it works. First, in Section~\ref{sec:uima} \uima{} is introduced. After an in-depth introduction into the original framework designed by IBM, \uimafit{} will be explained. \uimafit{} builds on top of \uima{}, providing the developer with a native Java interface for creating and instantiating plug-ins. Strongly related to the framework introduced in Chapter~\ref{ch:implementation} are the two native scaling frameworks \uimacpe{} and \uimaas{}. 

\marginnote{Ich habe es zwar nicht benutzt, aber eine kleine Einführung in HDFS könnte nützlich sein. Ich werde häufiger (im Kontext von BigData) anmerken, dass Daten vermutlich von einem verteiltem Dateisystem, etwa einem HDFS kommen und dahin geschrieben werden.}

The second section of this chapter will be about \spark{}. While no advanced knowledge is needed to comprehend the usage of \spark{} as a distributed computation framework, it will still be a substantial part of the \uima{} scaling framework in Chapter~\ref{ch:implementation}. Thus, a rather superficial overview of its structure and distribution algorithm will be given.

Since numerous attempts have been made, scaling \uima{} in different settings, with varying implementation requirements, some related work will be presented in Section~\ref{sec:related}, namely Leo, providing a native Java interface for \uimaas{}, and v3NLP, a framework especially designed for usage in a medical environment and with plug-ins of such sort.

Although most important aspects and concepts of \uima{} are also defined in the specifications, some minor changes and additions were made in the implementations. Since the framework must handle the actual implementation, all the presented concepts will be taken from Apache \uima{} instead of the \uima{} specification of 2009.



\section{UIMA-Family}
\label{sec:uima}
Unstructured Information Management Architecture (UIMA) Version 1.0 itself is an \oasis{} standard from 2009\footurl{http://docs.oasis-open.org/uima/v1.0/uima-v1.0.html}{2018-09-03} that defines an interface for software components, or plug-ins, which are called analytics. Those analytics are supposed to analyze unstructured information and assign machine readable semantics to it. The standard also defines ways to represent and interchange this data between analytics in favor of interoperability and platform-independence. 

Apache \uima{} is the open-source implementation of said \uima{} specification. It is available for Java and C++, while its scaling solutions, \uimacpe{} and \uimaas{} are only available for Java, which is why this thesis focuses on the Java implementation. Since \uima{} and Apache \uima{} have very similar names, which may lead to confusion it is common practice to call the implementation simply \uima{} and explicitly state if talking about the specification. This practice will be adopted for the rest of the thesis.

Unbedingt bilder hinzufügen und establishen was eine Pipeline ist!!1!

\subsection{Apache UIMA}

Apache \uima{} is one of few general approaches to implement \nlp{} solutions and the only commonly known implementation of the specification with the same name. With a very modular architecture, \uima{} is a popular tool that can easily be applied to a majority of \nlp{} problems. A large part of the popularity of \uima{} stems from the large \dkpro{} collection of components, containing hundreds of analysis modules and precomputed language models \cite{eckartdecastilho-gurevych:2014:OIAF4HLT}, which are easily imported into existing Java projects with the build automation tool Apache Maven \cite{dkpro}.

A common problem with \uima{} is scaling \cite{divita2015scaling,epstein2012making,ramakrishnan2010building}. \uima{} itself provides two distinct interfaces to analyze larger collections of unstructured data, with one being \uimaas{} and the other being the more dated and less flexible \cpe{} \cite{OASIS:UIMA:2009}.


\subsection{UIMAfit}
\subsection{UIMA-CPE}
UIMA CPE ist der Vorgänger von UIMA-AS und basiert im Grunde darauf, dem User vollständige Macht zu geben um die Skalierung zu bewerkstelligen. Das geht natürlich vollkommen nach hinten los, da Dinge wie Cas Initializers nicht trivial zu konfigurieren sind. Außerdem musste sich der User selbstständig um Dinge wie reconfigure() und typeSystemInit() kümmern. 
Natürlich basiert CPE auch auf XML-Deskriptoren, für die kein UIMAfit/Leo existiert.

\subsection{UIMA-AS}
Das bisherige non+ultra. Man deployed pipelines (oder einzelne engines) als Services, die sich am broker registrieren. Anfragen werden an den Broker geschickt, der sie dann weiter sendet. Je nach Broker-Implementierung kann man hier sehr schön resilience zu bauen. Es gibt hier ein paar Dinge zu beachten, was thread-safety angeht. Außerdem ist fraglich ob UIMA-AS tatsächlich uneingeschränkt skalierbar ist, da der CollectionReader möglicherweise einen bottleneck darstellt. Problematisch ist in jedem Fall die Tatsache, dass das gesamte CAS wieder zurück geschickt wird. Das ist möglicherweise gar nicht gewollt, da in der Pipeline bereits consumer bereit stehen, die Dinge in Datenbanken etc schreiben.

Das ist ein wenig die Verteidigung für mein System, bei dem es absolut grauenvoll ist, wenn man die CAS wieder zurück schickt :D

Hier bietet sich auch ein Schaubild an.

\section{Apache Spark}


\marginnote{Ich bin sehr unzufrieden mit der related work in den Basics. Es passt hier absolut nicht rein. Ich werde das vermutlich bald wieder in das erste Kapitel Introduction schieben.}
\section{Related Work}
\label{sec:related}
Hier im Grunde alles was es an "Vorarbeiten" bzw. konkurrierende Ansätze gibt.

\subsection{Leo}
Leo ist für UIMA-AS was UIMAfit für UIMA ist. Leider leidet Leo unter einer sehr schwachen und verletzlichen Programmierung. Dies zeigen zum Einen die Inkompabilitäten zu UIMAfit, zum Anderen aber auch statische Code Analyse. Alles in allem aber ein brauchbares Tool und mein Go-To, sollte ich UIMA-AS noch einmal aufsetzen.

\subsection{v3NLP}
v3NLP ist auch ein scaling framework für NLP, was auf UIMA aufbaut. Es wurde damals speziell für cTAKES und MetaMap programmiert.


%In this chapter, we will cover the basics for the necessary technologies used throughout the evaluation. All of these are concrete implementations of more general concepts and may be exchanged for similar products. However, the following products were chosen, mainly because they are Open Source\footurl{https://svn.apache.org/viewvc/uima/}{2018-02-27}\footurl{https://github.com/docker}{2018-02-27}\footurl{https://github.com/apache/hadoop}{2018-02-27}\footurl{https://github.com/apache/spark}{2018-02-27}\footurl{https://github.com/apache/kafka}{2018-02-27} but also because of their popularity and relevance in the industry.

% \input{basics/uima}
% \input{basics/docker}
% \input{basics/hadoop}
% \section{Spark}
% \section{Kafka}
