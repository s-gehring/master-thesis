% !TeX root = ../Main.tex

\chapter{Basics}
\label{ch:basics}
In this chapter, the two most important technologies for the framework are explained. This is necessary to get an understanding of the technical difficulties it challenges and how it works. First, in Section~\ref{sec:uima} \uima{} is introduced. After an in-depth introduction into the original framework designed by IBM, \uimafit{} will be explained. \uimafit{} builds on top of \uima{}, providing the developer with a native Java interface for creating and instantiating plug-ins. Strongly related to the framework introduced in Chapter~\ref{ch:implementation} are the two native scaling frameworks \uimacpe{} and \uimaas{}. 

\marginnote{Ich habe es zwar nicht benutzt, aber eine kleine Einführung in HDFS könnte nützlich sein. Ich werde häufiger (im Kontext von BigData) anmerken, dass Daten vermutlich von einem verteiltem Dateisystem, etwa einem HDFS kommen und dahin geschrieben werden.}

The second section of this chapter will be about \spark{}. While no advanced knowledge is needed to comprehend the usage of \spark{} as a distributed computation framework, it will still be a substantial part of the \uima{} scaling framework in Chapter~\ref{ch:implementation}. Thus, a rather superficial overview of its structure and distribution algorithm will be given.

Since numerous attempts have been made, scaling \uima{} in different settings, with varying implementation requirements, some related work will be presented in Section~\ref{sec:related}, namely Leo, providing a native Java interface for \uimaas{}, and v3NLP, a framework especially designed for usage in a medical environment and with plug-ins of such sort.

Although most important aspects and concepts of \uima{} are also defined in the specifications, some minor changes and additions were made in the implementations. Since the framework must handle the actual implementation, all the presented concepts will be taken from Apache \uima{} instead of the \uima{} specification of 2009.



\section{UIMA-Family}
\label{sec:uima}
Unstructured Information Management Architecture (UIMA) Version 1.0 itself is an \oasis{} standard from 2009\footurl{http://docs.oasis-open.org/uima/v1.0/uima-v1.0.html}{2018-09-03} that defines an interface for software components, or plug-ins, which are called analytics. Those analytics are supposed to analyze unstructured information and assign machine readable semantics to it. The standard also defines ways to represent and interchange this data between analytics in favor of interoperability and platform-independence. 

Apache \uima{} is the open-source implementation of said \uima{} specification. A common problem with Apache \uima{} is scaling \cite{divita2015scaling,epstein2012making,ramakrishnan2010building}. It  provides two distinct interfaces to analyze larger collections of unstructured data itself, with one being \uimaas{} and the other being the more dated and less flexible \cpe{} \cite{OASIS:UIMA:2009}.
Apache \uima{} is available for Java and C++, while its scaling solutions, \uimacpe{} and \uimaas{} are only available for Java, which is why this thesis focuses on the Java implementation. Since \uima{} and Apache \uima{} have very similar names, which may lead to confusion it is common practice to call the implementation simply \uima{} and explicitly state when talking about the specification. This practice will be adopted for the rest of the thesis.




Unbedingt bilder hinzufügen und establishen was eine Pipeline ist!!1!

\subsection{Apache UIMA}

Apache \uima{} is one of few general approaches to implement \nlp{} solutions and the only commonly known implementation of the specification with the same name. With a very modular architecture, \uima{} is a popular tool that can easily be applied to a majority of \nlp{} problems. A large part of the popularity of \uima{} stems from the large \dkpro{} collection of components, containing hundreds of analysis modules and precomputed language models \cite{eckartdecastilho-gurevych:2014:OIAF4HLT}, which are easily imported into existing Java projects with the build automation tool Apache Maven \cite{dkpro}.

\uima{} is usually used to process not a single but whole corpora of documents. A document in this sense is text, although the \uima{} specification permits other data types as well. However, \uima{} can not handle other data types without serializing it first. The \uima{} specification, as well as the implementation do not directly pose limitations to the document size but since documents are stored in native Java String variables, which itself are implemented as arrays of chars, the practical limit of documents sizes is dependent on the \jvm{} version and lies around one to two gigabytes \cite{so:javastrings} per document. In the context of \uima{}, such a document is called a \sofa{}.

An analytic in the \uima{} specification is called an \emph{Analysis Engine} in the implementation. For the most part, an \anen{} is code, that gets an input \cas{} and produces a number of analysis results on the \sofa{}. Common examples for \anens{} are Segmentation, Tokenization, and Part-of-Speech finding algorithms \cite{dkpro}. However, since an \anen{} contains arbitrary Java code any form of analysis can be instrumentalized by \uima{}. It is defined by an \xml{} Analysis Engine descriptor. Such an \anen{} can either be a so-called \emph{primitive} or an \emph{aggregate} engine. An aggregate engine simply contains one or more other \anens{}, that are aggregated into one single engine.

Analysis results are stored as annotations. An annotation has at least two attributes \lstinline[language=Java]|int begin| and \lstinline[language=Java]|int end|, indicating the start and end index of the \sofa{}s substring this annotation is associated with. This concept is theoretically extendable to any kind of \sofa{} that contains any sort of subsets, for example images or audio and video streams. However, this is impractical for reasons mentioned above. It is possible, but uncommon, to define other types of subsets on a string that -- for example -- permit multiple segments. Such subsets can be implemented in a custom implementation of the \lstinline|AnnotationBase| class, which in turn may omit the concept of a \lstinline|begin| and \lstinline|end|. Since an important reason of the popularity of \uima{} lies in the large \anen{} repositories and the possibility to reuse already published code, custom annotation implementations are rarely used because it would most likely lead to incompatibilities. However, sub classing the \lstinline|Annotation| class is often done to ensure type safety. Building such an annotation hierarchy leads to the creation of a Type System.

The Type System is a schema of all available types of annotations that may be associated with a current \sofa{}, thus it provides the meta data for the annotations. It is defined by an \xml{} Type System descriptor that is usually used by the \emph{JCasGen}, a Java code generator for \uima{} types. A \xml{} Type System descriptor may define an super Type System from which to inherit all types. This can be used to subclass types that are not defined in the current context and encapsulate all in a single larger Type System.

The \sofa{}, all analysis results in form of annotations that are compliant to an underlying Type System and the Type System itself are stored together in one large object, called a \cas{}. It is the sole input an \anen{} gets, since it incorporates the complete context needed. The annotations are stored in a larger index to optimize for efficient access. Furthermore, a \cas{} object provides different Views, lightweight versions of a \cas{}, that store their own \sofa{} and annotation index. These views are identified by a String, while the original data of the \cas{} is usually called the \emph{Initial View}.

Multiple Analysis Engines that form a complete flow of analysis are commonly known as a \emph{pipeline}. Since multiple \anens{} can be aggregated into one, a pipeline is usually an instance of a single aggregate analysis engine. Because of the convention to call analysis results annotations, \anens{} are often called \emph{Annotators}, which is not correct in general, since engines do not need to attach any annotations to the input \cas{}.


\subsection{UIMAfit}
Since \uima{} needs \xml{} descriptor files to configure and describe its components, especially pipelines and type systems, developing for it is very \xml{} heavy. Apache \uimafit{} is a framework that builds on \uima{}, providing an interface to programmatically describe, instantiate and deploy \uima{} components \cite{ogren-bethard:2009:SETQA-NLP}. \uimafit{} also provides an interface to dynamically write \xml{} descriptor files for \uima{} components. However, since it is able to instantiate and deploy said components without the need of \xml{} files, those are mostly ignored because of \uimafit{}. \uimaas{}, a native \uima{} scaling framework described in Section~\ref{ssec:uimaas}, is known to be widely incompatible with \uimafit{} which is what led to the creation of Leo, described in Section~\ref{ssec:leo}.

\uimafit{} has been part of the Apache \uima{} project since 2012 and is therefore officially supported \cite{github:uimafit}. 


\subsection{UIMA-CPE}
UIMA CPE ist der Vorgänger von UIMA-AS und basiert im Grunde darauf, dem User vollständige Macht zu geben um die Skalierung zu bewerkstelligen. Das geht natürlich vollkommen nach hinten los, da Dinge wie Cas Initializers nicht trivial zu konfigurieren sind. Außerdem musste sich der User selbstständig um Dinge wie reconfigure() und typeSystemInit() kümmern. 
Natürlich basiert CPE auch auf XML-Deskriptoren, für die kein UIMAfit/Leo existiert.

\subsection{UIMA-AS}
\label{ssec:uimaas}
Das bisherige non+ultra. Man deployed pipelines (oder einzelne engines) als Services, die sich am broker registrieren. Anfragen werden an den Broker geschickt, der sie dann weiter sendet. Je nach Broker-Implementierung kann man hier sehr schön resilience zu bauen. Es gibt hier ein paar Dinge zu beachten, was thread-safety angeht. Außerdem ist fraglich ob UIMA-AS tatsächlich uneingeschränkt skalierbar ist, da der CollectionReader möglicherweise einen bottleneck darstellt. Problematisch ist in jedem Fall die Tatsache, dass das gesamte CAS wieder zurück geschickt wird. Das ist möglicherweise gar nicht gewollt, da in der Pipeline bereits consumer bereit stehen, die Dinge in Datenbanken etc schreiben.

Das ist ein wenig die Verteidigung für mein System, bei dem es absolut grauenvoll ist, wenn man die CAS wieder zurück schickt :D

Hier bietet sich auch ein Schaubild an.

\section{Apache Spark}


\marginnote{Ich bin sehr unzufrieden mit der related work in den Basics. Es passt hier absolut nicht rein. Ich werde das vermutlich bald wieder in das erste Kapitel Introduction schieben.}
\section{Related Work}
\label{sec:related}
Hier im Grunde alles was es an "Vorarbeiten" bzw. konkurrierende Ansätze gibt.

\subsection{Leo}
\label{ssec:leo}
Leo ist für UIMA-AS was UIMAfit für UIMA ist. Leider leidet Leo unter einer sehr schwachen und verletzlichen Programmierung. Dies zeigen zum Einen die Inkompabilitäten zu UIMAfit, zum Anderen aber auch statische Code Analyse. Alles in allem aber ein brauchbares Tool und mein Go-To, sollte ich UIMA-AS noch einmal aufsetzen.

\subsection{v3NLP}
v3NLP ist auch ein scaling framework für NLP, was auf UIMA aufbaut. Es wurde damals speziell für cTAKES und MetaMap programmiert.


%In this chapter, we will cover the basics for the necessary technologies used throughout the evaluation. All of these are concrete implementations of more general concepts and may be exchanged for similar products. However, the following products were chosen, mainly because they are Open Source\footurl{https://svn.apache.org/viewvc/uima/}{2018-02-27}\footurl{https://github.com/docker}{2018-02-27}\footurl{https://github.com/apache/hadoop}{2018-02-27}\footurl{https://github.com/apache/spark}{2018-02-27}\footurl{https://github.com/apache/kafka}{2018-02-27} but also because of their popularity and relevance in the industry.

% \input{basics/uima}
% \input{basics/docker}
% \input{basics/hadoop}
% \section{Spark}
% \section{Kafka}
